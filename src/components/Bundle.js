import { useEffect, useRef, useState } from "react";
import * as faceapi from "face-api.js";

// Enabling Camera
const enableCamera = async (videoRef) => {
  try {
    const stream = await navigator.mediaDevices.getUserMedia({
      video: true,
    });
    if (videoRef.current) {
      videoRef.current.srcObject = stream;
    }
  } catch (error) {
    console.log("Error accessing the camera: " + error);
  }
};

// Disabling Camera ==> not working
const disableCamera = async (videoRef) => {
  try {
    const stream = videoRef.current.srcObject;
    const tracks = stream.getTracks();
    tracks[0].stop();
  } catch (error) {
    console.log("Error accessing the camera: " + error);
  }
};

const Bundle = ({currentContentId, closeBundle, uploadReply}) => {
  const videoRef = useRef(null);
  const [capturedDataURL, setCapturedDataURL] = useState(null);
  const [isStreaming, setIsStreaming] = useState(true);

  // detect emojiì— ì“¸ useRef ì„ ì–¸
  const imgRef = useRef();
  const canvasRef = useRef();
  // detectingì´ failí–ˆì„ ê²½ìš°
  const [detectionFail, setDetectionFail] = useState(false);

  // emojië¥¼ ì €ìž¥í•  useRef ì„ ì–¸
  const [currentEmoji, setCurrentEmoji] = useState(null);

  // biggest emotionì„ ì¶”ì¶œí•  í•¨ìˆ˜ biggestOf ì„ ì–¸
  const biggestOf = (detectedExpressions) => {
    var keys = Object.keys(detectedExpressions)
    var max = keys[0]
    var i;
    for (i=1; i<keys.length; i++){
      if (detectedExpressions[keys[i]]>detectedExpressions[max]){
        max = keys[i];
      }
    }
    return max;
  };

  // emotionì„ emojië¡œ ë³€í™˜í•  ì˜¤ë¸Œì íŠ¸ mapEmoji ì„¤ì •
  const mapEmoji = {
    angry: "ðŸ‘¿",
    disgusted: "ðŸ¤¢",
    fearful: "ðŸ˜¨",
    happy: "ðŸ˜Š",
    neutral: "ðŸ˜",
    sad: "ðŸ˜¥",
    surprised: "ðŸ˜²"
  };

  const handleImage = async () => {
    const detections = await faceapi
      .detectAllFaces(imgRef.current, new faceapi.TinyFaceDetectorOptions())
      .withFaceLandmarks()
      .withFaceExpressions();

    const expressions = detections[0].expressions
    const box = detections[0].detection.box
    console.log(box);
    console.log(expressions);
    // currentEmojië¥¼ ìµœëŒ€ê°€ì¤‘ì¹˜ ê°ì • emojië¡œ ì„¸íŒ…
    setCurrentEmoji(mapEmoji[ biggestOf(expressions) ]);

    // canvas ì´ˆê¸°í™”
    const canvas = canvasRef.current;
    const context = canvas.getContext("2d");
    context.clearRect(0, 0, canvas.width, canvas.height);

    faceapi.matchDimensions(canvas, imgRef.current);

    const resizedDetections = faceapi.resizeResults(detections, canvas);
    faceapi.draw.drawDetections(canvas, resizedDetections);
    // faceapi.draw.drawFaceExpressions(canvas, resizedDetections);
    // faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);
  };

  useEffect(() => {
    const loadModels = async () => {
      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri("/models"),
        faceapi.nets.faceLandmark68Net.loadFromUri("/models"),
        faceapi.nets.faceRecognitionNet.loadFromUri("/models"),
        faceapi.nets.faceExpressionNet.loadFromUri("/models"),
      ]);
    };

    loadModels();
  }, []);

  useEffect(() => {
    enableCamera(videoRef); // Enable camera on component mount
  }, []);

  // í˜„ìž¬ ì¹´ë©”ë¼ í™”ë©´ ìº¡ì³ ë° ìº”ë²„ìŠ¤ì— ê·¸ë¦¬ê¸°
  const capturePhoto = () => {
    const video = videoRef.current;

    if (video) {
      const canvas = document.createElement("canvas");
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;

      const context = canvas.getContext("2d");
      context.drawImage(video, 0, 0, canvas.width, canvas.height);

      canvas.toBlob((blob) => {
        if (blob) {
          const reader = new FileReader();
          reader.onloadend = () => {
            const dataURL = reader.result;
            setCapturedDataURL(dataURL);
            setIsStreaming(false); // Stop streaming after capturing image
          };
          reader.readAsDataURL(blob);
        } else {
          console.log("Failed to capture image. Please try again.");
        }
      }, "image/jpeg");
    }
  };

  const retakePhoto = () => {
    setIsStreaming(true); // Resume camera streaming
    setCapturedDataURL(null); // Reset captured image data

    const video = videoRef.current;
    if (video && video.srcObject) {
      const tracks = video.srcObject.getTracks();
      tracks.forEach((track) => track.stop()); // Stop the existing tracks
      video.srcObject = null; // Clear the video source object
    }

    enableCamera(videoRef); // Re-enable the camera stream
  };

  const handleImgLoad = () => {
    handleImage();
  };

  // ë°”ë¡œ ì°ì§€ ì•Šì„ ê²½ìš°
  const notNow = () => {
    disableCamera();
    closeBundle();
  }

  // ì°ì€ ì‚¬ì§„ ì´ëª¨ì§€ ì €ìž¥ ë° ë²ˆë“¤ ë‹«ê¸°(ì´ëª¨ì§€ë¦¬ìŠ¤íŠ¸ë¡œ ë„˜ì–´ê°€ê¸°)
  const savePhoto = () => {
    // { contentId, replyId, replyEmoji, replyTxt, timestamp }
    uploadReply({contentId: currentContentId, replyId: Date.now(), replyEmoji: currentEmoji, timestamp: Date.now()});
    disableCamera();
    closeBundle();
  }

  return (
    <div className="w-full h-full flex items-center justify-center bg-gray-200">
      <div>
        {/* content */}
        <div>
        {isStreaming ? (
          <video id="videoElement" autoPlay ref={videoRef}></video>
        ) : (
          <div>
            <h2>Camera Stream Stopped</h2>
            {capturedDataURL ? (
              <div>
                <canvas
                  ref={canvasRef}
                  className="bg-transparent absolute"
                  width="940"
                  height="650"
                />
                <img
                  src={capturedDataURL}
                  alt="Captured"
                  ref={imgRef}
                  onLoad={handleImgLoad}
                />
                <button onClick={retakePhoto}>Retake</button>
                <button onClick={savePhoto}>OK</button>
              </div>
            ) : (
              <p>No captured image available.</p>
            )}
          </div>
        )}
        {isStreaming && !capturedDataURL && (
          <button onClick={capturePhoto}>Capture and Save</button>
        )}
    </div>
        {/* close Bundle button */}
        <button
          className="bg-blue-500 text-white px-2 rounded mt-4"
          onClick={notNow}
        >
          Not now!
        </button>

      </div>
    </div>
  );
}

export default Bundle;